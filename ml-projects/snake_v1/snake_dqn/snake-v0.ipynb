{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from keras import utils\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from collections import deque\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from enum import Enum\n",
    "from PIL import Image\n",
    "\n",
    "utils.disable_interactive_logging()\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TName(Enum):\n",
    "    COLLISION = 1\n",
    "    EXTRA_VISIT = 2\n",
    "    WALL_BODY_TRAP = 3\n",
    "    BODY_TRAP = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SnakeGameEnv:\n",
    "    def __init__(self, grid_size=10):\n",
    "        self.grid_size = grid_size\n",
    "        self.grid_area = grid_size * grid_size\n",
    "        self.grid = np.zeros((grid_size, grid_size), dtype=np.uint8)\n",
    "        self.clock_wise = [(0, 1), (1, 0), (0, -1), (-1, 0)]\n",
    "        self.edges = [0, grid_size-1]\n",
    "        self.MAX_CELL_VISIT = 2\n",
    "        self.MOVE_PENALTY = 0\n",
    "        self.LOOPING_PENALTY = -5\n",
    "        self.COLLISION_PENALTY = -10\n",
    "        self.FOOD_REWARD = 10\n",
    "        self.EDGE_MOVE_REWARD = 1\n",
    "        self.reset()\n",
    "\n",
    "    def generate_food(self):\n",
    "        return random.choice([(x, y) for x in range(self.grid_size) for y in range(self.grid_size) if (x, y) not in self.snake])\n",
    "    \n",
    "    def _is_collision(self, cell):\n",
    "        if (\n",
    "            cell in self.snake\n",
    "            or cell[0] < 0\n",
    "            or cell[0] >= self.grid_size\n",
    "            or cell[1] < 0\n",
    "            or cell[1] >= self.grid_size\n",
    "        ):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def _update_grid(self):\n",
    "        self.grid = np.zeros((self.grid_size, self.grid_size), dtype=np.uint8)\n",
    "        # Snake body cells as 1\n",
    "        for r, c in self.snake:\n",
    "            self.grid[r, c] = 1\n",
    "\n",
    "        # Food cell as 2\n",
    "        self.grid[self.food[0], self.food[1]] = 2\n",
    "\n",
    "    def _body_within_radius(self, radius=5):\n",
    "        head = self.snake[0]\n",
    "        start_row, start_col = min(max(head[0] - radius // 2, 0), 5) , min(max(head[1] - radius // 2, 0), 5)\n",
    "        end_row, end_col = start_row + radius, start_col + radius \n",
    "        \n",
    "        count = 0\n",
    "        for r in range(start_row, end_row):\n",
    "            for c in range(start_col, end_col):\n",
    "                if self.grid[r, c] == 1:\n",
    "                    count += 1\n",
    "\n",
    "        return count\n",
    "\n",
    "    def _visit_limit_reached(self, direction):\n",
    "        dr, dc = direction\n",
    "        head_r, head_c = self.snake[0]\n",
    "        r, c = head_r + dr, head_c + dc\n",
    "\n",
    "        if 0 <= r < self.grid_size and 0 <= c < self.grid_size:\n",
    "            return self.visit_count[r, c] == self.MAX_CELL_VISIT\n",
    "        return 0\n",
    "    \n",
    "    def _is_surrounded_by_body(self, direction, start=None):\n",
    "        start_row, start_col = self.snake[0][0] + direction[0], self.snake[0][1] + direction[1]\n",
    "        if start:\n",
    "            start_row, start_col = start\n",
    "        if not 0 <= start_row < self.grid_size or not 0 <= start_col < self.grid_size or self.grid[start_row, start_col] == 1: \n",
    "            return False\n",
    "\n",
    "        moves = [(0, 1), (0, -1), (1, 0), (-1, 0)]\n",
    "        visited = [[False] * self.grid_size for _ in range(self.grid_size)]        \n",
    "        queue = deque([(start_row, start_col)])\n",
    "        \n",
    "        while queue:\n",
    "            row, col = queue.popleft()\n",
    "            visited[row][col] = True\n",
    "            \n",
    "            # If we reach boundary then it is not close loop\n",
    "            if row == 0 or row == self.grid_size - 1 or col == 0 or col == self.grid_size - 1:\n",
    "                return False \n",
    "            \n",
    "            for dr, dc in moves:\n",
    "                r, c = row + dr, col + dc\n",
    "                if 0 <= r < self.grid_size and 0 <= c < self.grid_size and not visited[r][c] and self.grid[r, c] == 0:\n",
    "                    queue.append((r, c))\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def _open_area(self, direction, start=None):\n",
    "        start_row, start_col = self.snake[0][0] + direction[0], self.snake[0][1] + direction[1]\n",
    "        if start:\n",
    "            start_row, start_col = start       \n",
    "\n",
    "        if not 0 <= start_row < self.grid_size or not 0 <= start_col < self.grid_size or self.grid[start_row, start_col] == 1: \n",
    "            return -1\n",
    "        visited = set()\n",
    "        queue = deque([(start_row, start_col)])\n",
    "\n",
    "        area = 0\n",
    "        while queue:\n",
    "            r, c = queue.popleft()\n",
    "\n",
    "            if (r, c) not in visited and 0 <= r < self.grid_size and 0 <= c < self.grid_size and self.grid[r, c] != 1:\n",
    "                visited.add((r, c))\n",
    "                area += 1\n",
    "\n",
    "                # Check adjacent cells\n",
    "                directions = [(0, 1), (0, -1), (1, 0), (-1, 0)]\n",
    "                for dr, dc in directions:\n",
    "                    new_r, new_c = r + dr, c + dc\n",
    "                    queue.append((new_r, new_c))\n",
    "\n",
    "        return area\n",
    "\n",
    "    def get_state(self):\n",
    "        head = self.snake[0]\n",
    "        coord_l = (head[0], head[1]-1)\n",
    "        coord_r = (head[0], head[1]+1)\n",
    "        coord_u = (head[0]-1, head[1])\n",
    "        coord_d = (head[0]+1, head[1])\n",
    "\n",
    "        dir_l = self.direction == (0, -1)\n",
    "        dir_r = self.direction == (0, 1)\n",
    "        dir_u = self.direction == (-1, 0)\n",
    "        dir_d = self.direction == (1, 0)\n",
    "\n",
    "        cur_dir = self.direction\n",
    "        idx = self.clock_wise.index(cur_dir)\n",
    "        cur_dir_l = self.clock_wise[(idx - 1) % 4]\n",
    "        cur_dir_r = self.clock_wise[(idx + 1) % 4]\n",
    "        \n",
    "        head_on_edge = head[0] in self.edges or head[1] in self.edges\n",
    "        self.area_l = self.area_r = 0\n",
    "        if head_on_edge:\n",
    "            self.area_l = self._open_area(cur_dir_l)\n",
    "            self.area_r = self._open_area(cur_dir_r)\n",
    "            if self.area_l == -1 or self.area_r == -1: self.area_l = self.area_r = -1\n",
    "        \n",
    "        self.min_entry_area = 0.6 * (self.grid_area - self.snake_len)\n",
    "\n",
    "        state = [\n",
    "            # Danger Straight\n",
    "            (dir_r and self._is_collision(coord_r)) or\n",
    "            (dir_l and self._is_collision(coord_l)) or\n",
    "            (dir_u and self._is_collision(coord_u)) or\n",
    "            (dir_d and self._is_collision(coord_d)),\n",
    "\n",
    "            # Danger Right\n",
    "            (dir_u and self._is_collision(coord_r)) or\n",
    "            (dir_r and self._is_collision(coord_d)) or\n",
    "            (dir_d and self._is_collision(coord_l)) or\n",
    "            (dir_l and self._is_collision(coord_u)),\n",
    "\n",
    "            # Danger Left\n",
    "            (dir_u and self._is_collision(coord_l)) or\n",
    "            (dir_r and self._is_collision(coord_u)) or\n",
    "            (dir_d and self._is_collision(coord_r)) or\n",
    "            (dir_l and self._is_collision(coord_d)),\n",
    "            \n",
    "            # Check if next move head will be surrounded by snake body\n",
    "            self._is_surrounded_by_body(cur_dir) and self._open_area(cur_dir) < self.min_entry_area,\n",
    "            self._is_surrounded_by_body(cur_dir_l) and self._open_area(cur_dir_l) < self.min_entry_area,\n",
    "            self._is_surrounded_by_body(cur_dir_r) and self._open_area(cur_dir_r) < self.min_entry_area,\n",
    "            \n",
    "            # Check which enclosed area is smaller\n",
    "            self.area_r < self.area_l,    # Right is smaller\n",
    "            self.area_l < self.area_r,    # Left is smaller\n",
    "\n",
    "            # Check the cell visit limit\n",
    "            self._visit_limit_reached(cur_dir),   # Straight\n",
    "            self._visit_limit_reached(cur_dir_r),   # Right\n",
    "            self._visit_limit_reached(cur_dir_l),   # Left\n",
    "\n",
    "            # Move direction\n",
    "            dir_l,\n",
    "            dir_r,\n",
    "            dir_u,\n",
    "            dir_d,\n",
    "\n",
    "            head_on_edge,\n",
    "            # Food Location\n",
    "            self.food[1] > head[1],     # food is down\n",
    "            self.food[1] < head[1],     # food is up\n",
    "            self.food[0] < head[0],     # food is left\n",
    "            self.food[0] > head[0],     # food is right\n",
    "            self.food[0] == head[0],    # food is in the same row\n",
    "            self.food[1] == head[1]     # food is in the same col\n",
    "        ]\n",
    "\n",
    "        return np.array(state, dtype=int)\n",
    "    \n",
    "    def step(self, action):\n",
    "        idx = self.clock_wise.index(self.direction)\n",
    "        \n",
    "        if action == 0:\n",
    "            self.direction = self.clock_wise[idx]\n",
    "        elif action == 1:\n",
    "            next_idx = (idx + 1) % 4\n",
    "            self.direction = self.clock_wise[next_idx]\n",
    "        elif action == 2:\n",
    "            next_idx = (idx - 1) % 4\n",
    "            self.direction = self.clock_wise[next_idx]\n",
    "\n",
    "        new_head = (self.snake[0][0]+self.direction[0], self.snake[0][1]+self.direction[1])\n",
    "\n",
    "        # Check for the collisions\n",
    "        if self._is_collision(new_head):\n",
    "            self.done = True\n",
    "            return self.COLLISION_PENALTY, self.done\n",
    "        \n",
    "        # Check for any cell visited extra to avoid loop movement\n",
    "        self.visit_count[new_head] += 1\n",
    "        if self.visit_count[new_head] > self.MAX_CELL_VISIT:\n",
    "            self.done = True\n",
    "            reward = self.LOOPING_PENALTY\n",
    "            return reward, self.done\n",
    "        \n",
    "        # Check for traps formed by body and wall\n",
    "        head = self.snake[0]\n",
    "        if (head[0] in self.edges or head[1] in self.edges) and self.area_l != self.area_r:\n",
    "            open_area = self._open_area(self.direction, new_head)\n",
    "            if open_area < max(self.area_l, self.area_r):\n",
    "                self.done = True\n",
    "                reward = self.LOOPING_PENALTY\n",
    "                return reward, self.done\n",
    "        \n",
    "        # Check for body loop traps \n",
    "        if self._is_surrounded_by_body(self.direction, new_head) and self._open_area(self.direction, new_head) < self.min_entry_area:\n",
    "            self.done = True\n",
    "            reward = self.LOOPING_PENALTY\n",
    "            return reward, self.done\n",
    "\n",
    "        # Move the snake\n",
    "        self.snake.insert(0, new_head)\n",
    "        \n",
    "        reward = 0\n",
    "        if new_head[0] in self.edges or new_head[1] in self.edges:\n",
    "            reward = self.EDGE_MOVE_REWARD\n",
    "\n",
    "        # Check if the snake ate the food\n",
    "        if new_head == self.food:\n",
    "            self.food = self.generate_food()\n",
    "            self.score += 1\n",
    "            self.snake_len += 1\n",
    "            reward = self.FOOD_REWARD\n",
    "            self.visit_count = np.zeros((self.grid_size, self.grid_size), dtype=np.uint8)\n",
    "        else:\n",
    "            self.snake.pop()\n",
    "            # reward = self.MOVE_PENALTY\n",
    "        \n",
    "        self._update_grid()\n",
    "\n",
    "        return reward, self.done\n",
    "    \n",
    "    def reset(self):\n",
    "        mid = self.grid_size // 2\n",
    "        self.snake = [(mid, mid)]\n",
    "        self.direction = (0, 1)\n",
    "        self.snake_len = len(self.snake)\n",
    "        self.food = self.generate_food()\n",
    "        self._update_grid()\n",
    "        self.visit_count = np.zeros((self.grid_size, self.grid_size), dtype=np.uint8)\n",
    "        self.score = 0\n",
    "        self.done = False\n",
    "        return self.get_state()\n",
    "    \n",
    "    def render(self):\n",
    "        img = self.get_image()\n",
    "        # Resize the RGB image to the desired dimensions\n",
    "        img_resized = cv2.resize(img, (300, 300), interpolation=cv2.INTER_NEAREST)\n",
    "        cv2.imshow(\"SnakeDQN\", np.array(img_resized))\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            return\n",
    "    \n",
    "    def get_image(self):\n",
    "        # Define color mapping\n",
    "        colors = {\n",
    "            0: (255, 218, 51), # Snake Head\n",
    "            1: (255, 0, 0),   # Snake Body(Green)\n",
    "            2: (0, 255, 0)    # Food (Red)\n",
    "        }\n",
    "\n",
    "        # Create an RGB image\n",
    "        rgb_frame = np.zeros((self.grid_size, self.grid_size, 3), dtype=np.uint8)\n",
    "\n",
    "        for x, y in self.snake:     # Fill the Snake cells\n",
    "            rgb_frame[x, y, :] = colors[1]\n",
    "        rgb_frame[self.food[0], self.food[1], :] = colors[2]    # Fill food cell\n",
    "\n",
    "        rgb_frame[self.snake[0][0], self.snake[0][1]] = colors[0]\n",
    "\n",
    "        img = Image.fromarray(rgb_frame, 'RGB')\n",
    "        return np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=10000)\n",
    "        self.memory_len = 0\n",
    "        self.min_replay_size = 500\n",
    "        self.replay_frequency = 5\n",
    "        self.batch_size = 200\n",
    "        self.gamma = 0.95\n",
    "        self.epsilon = 1\n",
    "        self.epsilon_decay = 0.97\n",
    "        self.epsilon_min = 0.01\n",
    "        self.model = self.build_model()\n",
    "        self.target_model = self.build_model()\n",
    "        self.target_model_update_frequency = 50\n",
    "        self.update_target_model()\n",
    "    \n",
    "    def build_model(self):\n",
    "        model = Sequential([\n",
    "            Input(shape=self.state_size),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dense(self.action_size, activation='linear')\n",
    "        ]) \n",
    "        model.compile(loss='mse', optimizer=Adam(learning_rate=0.001))\n",
    "        return model\n",
    "    \n",
    "    def update_target_model(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "    \n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return np.random.randint(0, self.action_size)\n",
    "        return np.argmax(self.model.predict(np.expand_dims(state, axis=0))[0])\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        self.memory_len += 1\n",
    "\n",
    "    def decay_epsilon(self):\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "    \n",
    "    def replay(self):\n",
    "        if self.memory_len < self.min_replay_size:\n",
    "            return\n",
    "        \n",
    "        minibatch = random.sample(self.memory, self.batch_size)\n",
    "        \n",
    "        states = np.array([experience[0] for experience in minibatch])\n",
    "        qs_list = self.model.predict(states)\n",
    "\n",
    "        next_states = np.array([experience[3] for experience in minibatch])\n",
    "        next_qs_list = self.target_model.predict(next_states)\n",
    "\n",
    "        X, y = [], []\n",
    "        \n",
    "        for index, (state, action, reward, next_state, done) in enumerate(minibatch):\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target += self.gamma * np.amax(next_qs_list[index])\n",
    "            \n",
    "            qs = qs_list[index]\n",
    "            qs[action] = target\n",
    "\n",
    "            X.append(state)\n",
    "            y.append(qs)\n",
    "        \n",
    "        self.model.fit(np.array(X), np.array(y), batch_size=self.batch_size, verbose=0, epochs=1)\n",
    "\n",
    "        self.decay_epsilon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = SnakeGameEnv(grid_size=10)\n",
    "agent = DQNAgent(state_size=(22,), action_size=3)\n",
    "agent.model = load_model('models/v0.5/snake_model-51.h5')\n",
    "agent.epsilon = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(num_episodes=10000):\n",
    "    rewards_collected = []\n",
    "    rewards_chunk_size = agent.target_model_update_frequency\n",
    "    high_score = 25\n",
    "\n",
    "    for episode in range(1, num_episodes+1):\n",
    "        state = env.reset()\n",
    "        episode_reward = 0\n",
    "\n",
    "        while not env.done:\n",
    "            env.render()\n",
    "            action = agent.act(state)\n",
    "            reward, done = env.step(action)\n",
    "            next_state = env.get_state()\n",
    "\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            episode_reward += reward\n",
    "\n",
    "            state = next_state\n",
    "        \n",
    "        rewards_collected.append(episode_reward)\n",
    "        \n",
    "        if episode % agent.replay_frequency == 0:\n",
    "            agent.replay()\n",
    "\n",
    "        if env.score > high_score:\n",
    "            high_score = env.score\n",
    "            agent.model.save(f\"models-1/snake_model-{high_score}.h5\")\n",
    "            \n",
    "        print(f\"Episode: {episode} Reward: {episode_reward} Score: {env.score}\")\n",
    "        \n",
    "        # Update target model after every (50) episodes and show the rewards collected\n",
    "        if episode % agent.target_model_update_frequency == 0:\n",
    "            # Show avg reward collected for the last 50 episodes\n",
    "            print(f\"Last {rewards_chunk_size} rewards avg: {sum(rewards_collected[-rewards_chunk_size:])/rewards_chunk_size}\")\n",
    "            print(f\"Epsilon: {agent.epsilon}\")\n",
    "            agent.update_target_model()\n",
    "        \n",
    "        # After each episode, clear the session to release memory\n",
    "        tf.keras.backend.clear_session()\n",
    "    \n",
    "    moving_avg = np.convolve(rewards_collected, np.ones(rewards_chunk_size)/rewards_chunk_size, mode='valid')\n",
    "    plt.plot([i for i in range(num_episodes-rewards_chunk_size+1)], moving_avg)\n",
    "    plt.ylabel(f\"{rewards_chunk_size} Rewards MA\")\n",
    "    plt.xlabel(f\"Episode\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model(num_episodes=1500)\n",
    "# agent.model.save('snake_model_final-1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(num_episodes=50):\n",
    "    agent.epsilon = 0\n",
    "    high_score = 0\n",
    "    total_score = 0\n",
    "    refresh_frequency = 50\n",
    "\n",
    "    for episode in range(1, num_episodes + 1):\n",
    "        state = env.reset()\n",
    "        episode_reward = 0\n",
    "        step_count = 0\n",
    "\n",
    "        while not env.done:\n",
    "            env.render()\n",
    "            # Choose actions greedily (exploit) based on the learned Q-values\n",
    "            action = agent.act(state)\n",
    "            reward, done = env.step(action)\n",
    "            next_state = env.get_state()\n",
    "\n",
    "            state = next_state\n",
    "            step_count += 1\n",
    "            if step_count % refresh_frequency == 0:\n",
    "                tf.keras.backend.clear_session()\n",
    "        print(f\"Score: {env.score}\")\n",
    "        if env.score > high_score:\n",
    "            high_score= env.score\n",
    "        total_score += env.score\n",
    "        print(env.terminations)\n",
    "\n",
    "    print(f\"Avg score: {total_score // num_episodes}\")\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"d:\\Projects\\Machine Learning\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2341, in predict_function  *\n        return step_function(self, iterator)\n    File \"d:\\Projects\\Machine Learning\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2327, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\Projects\\Machine Learning\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2315, in run_step  **\n        outputs = model.predict_step(data)\n    File \"d:\\Projects\\Machine Learning\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2283, in predict_step\n        return self(x, training=False)\n    File \"d:\\Projects\\Machine Learning\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"d:\\Projects\\Machine Learning\\venv\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 21), found shape=(None, 22)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_model()\n",
      "Cell \u001b[1;32mIn[9], line 15\u001b[0m, in \u001b[0;36mtest_model\u001b[1;34m(num_episodes)\u001b[0m\n\u001b[0;32m     13\u001b[0m env\u001b[39m.\u001b[39mrender()\n\u001b[0;32m     14\u001b[0m \u001b[39m# Choose actions greedily (exploit) based on the learned Q-values\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m action \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mact(state)\n\u001b[0;32m     16\u001b[0m reward, done \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(action)\n\u001b[0;32m     17\u001b[0m next_state \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mget_state()\n",
      "Cell \u001b[1;32mIn[5], line 35\u001b[0m, in \u001b[0;36mDQNAgent.act\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrand() \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepsilon:\n\u001b[0;32m     34\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_size)\n\u001b[1;32m---> 35\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39margmax(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict(np\u001b[39m.\u001b[39;49mexpand_dims(state, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m))[\u001b[39m0\u001b[39m])\n",
      "File \u001b[1;32md:\\Projects\\Machine Learning\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filedvrizkw7.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"d:\\Projects\\Machine Learning\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2341, in predict_function  *\n        return step_function(self, iterator)\n    File \"d:\\Projects\\Machine Learning\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2327, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\Projects\\Machine Learning\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2315, in run_step  **\n        outputs = model.predict_step(data)\n    File \"d:\\Projects\\Machine Learning\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2283, in predict_step\n        return self(x, training=False)\n    File \"d:\\Projects\\Machine Learning\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"d:\\Projects\\Machine Learning\\venv\\lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 21), found shape=(None, 22)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "test_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c312d2f3273360a0ac5e60645e1d5c432d326db55f1aa9ac69d7346cfdfb2b41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
